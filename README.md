# Awesome Vision and Language PreTrain Models (PTMs)
Maintained by [Yang Gao]() (ustcgaoy01@gmail.com) Last Update on 12/05/2020. 

Due to the large amount of research in this field, we mainly focus on research related to transfer learning, multimodal learning and SOTA modeling techniques for improving model performance or efficiency.

## Table of Contents
* [Surveys](#survey)
* [Transformers](#transformers)
* [Well-Known Large-Scale Pretrain Models](#well-known-large-scale-pretrain-models)
* [Vision-Only PTMs](#vision-only-ptms)
* [Language-Only PTMs](#language-only-ptms)
* [MultiModal/Vision-Language PTMs](#multimodal-ptms)

## Survey
[Efficient Transformers: A Survey](https://arxiv.org/pdf/2009.06732.pdf)

[Transformers: State-of-the-Art Natural Language Processing](https://www.aclweb.org/anthology/2020.emnlp-demos.6.pdf)

## Transformers
![](https://github.com/AlenUbuntu/Awesome-Vision-and-Language-PreTrain-Models/blob/main/transformers.png)

**Performer**

[Masked language modeling for proteins via linearly scalable long-context transformers](https://arxiv.org/pdf/2006.03555.pdf), arXiv, 2020.

**Linformer**

[Linformer: Selfattention with linear complexity.](https://arxiv.org/pdf/2006.04768.pdf), arXiv, 2020.

**Linear Transformers**

[Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention](https://arxiv.org/pdf/2006.16236.pdf), arXiv, 2020.

**BigBird**

[Big bird: Transformers for longer sequences.](https://arxiv.org/pdf/2007.14062.pdf), arXiv, 2020.

**Synthesizer**

[Synthesizer: Rethinking self-attention in transformer models.](https://arxiv.org/pdf/2005.00743.pdf), arXiv, 2020.

**ETC**

[Etc: Encoding long and structured data in transformers.](https://arxiv.org/pdf/2004.08483.pdf), arXiv, 2020.

**Longformer**

[Longformer: The long-document transformer.](https://arxiv.org/pdf/2004.05150.pdf), arXiv, 2020.

**Sinkhorn Transformer**

[Sparse sinkhorn attention.](https://arxiv.org/pdf/2002.11296.pdf), arXiv, 2020.

**Compressive Transformer**

[Compressive transformers for long-range sequence modelling.](https://arxiv.org/pdf/1911.05507.pdf), ICLR, 2020.

**Routing Transformer**

[Efficient Content-Based Sparse Attention with Routing Transformers](https://arxiv.org/pdf/2003.05997.pdf), arXiv, 2020.

**Reformer**

[Reformer: The efficient transformer.](https://arxiv.org/pdf/2001.04451.pdf), ICLR, 2020.

**Sandwitch Transformer**

[Improving Transformer Models by Reordering their Sublayers](https://www.aclweb.org/anthology/2020.acl-main.270.pdf), ACL, 2020.

**Highway Transformer**

[Highway Transformer: Self-Gating Enhanced Self-Attentive Networks](https://www.aclweb.org/anthology/2020.acl-main.616.pdf), ACL, 2020.

**Cascade Transformer**

[The Cascade Transformer: an Application for Efficient Answer Sentence Selection](https://www.aclweb.org/anthology/2020.acl-main.504.pdf), ACL, 2020.

**Hard-Aware Transformer**

[HAT: Hardware-Aware Transformers for Efficient Natural Language Processing](https://www.aclweb.org/anthology/2020.acl-main.686.pdf), ACL, 2020.

**Multimodal Transformer**

[Multimodal Transformer for Multimodal Machine Translation.](https://www.aclweb.org/anthology/2020.acl-main.400.pdf), ACL, 2020.

**HetGT**

[Heterogeneous Graph Transformer for Graph-to-Sequence Learning](https://www.aclweb.org/anthology/2020.acl-main.640.pdf), ACL, 2020.

**Memory-driven Transformer**

[Generating Radiology Reports via Memory-driven Transformer](https://www.aclweb.org/anthology/2020.emnlp-main.112.pdf), EMNLP, 2020.

**Axial Transformer**

[Axial attention in multidimensional transformers.](https://arxiv.org/pdf/1912.12180.pdf), arXiv, 2019.

**Sparse Transformer**

[Generating long sequences with sparse transformers.](https://arxiv.org/pdf/1904.10509.pdf), arXiv, 2019.

**Style Transformer**

[Style Transformer: Unpaired Text Style Transfer without Disentangled Latent Representation](https://www.aclweb.org/anthology/P19-1601.pdf), ACL, 2019.

**Transformer-XL**

[Transformer-xl: Attentive language models beyond a fixed-length context.](https://arxiv.org/pdf/1901.02860.pdf), ACL, 2019.

**Adaptive-Span**

[Adaptive Attention Span in Transformers](https://www.aclweb.org/anthology/P19-1032.pdf), ACL, 2019.

**Set Transformer**

[Set transformer: A framework for attention-based permutation-invariant neural networks.](https://arxiv.org/pdf/1810.00825.pdf), ICML, 2019.

**Image Transformer**

[Image transformer.](https://arxiv.org/pdf/1802.05751.pdf), ICML, 2018.

**Memory Compressed**

[Generating wikipedia by summarizing long sequences](https://arxiv.org/pdf/1801.10198.pdf), ICLR, 2018.

**Transformer**

[Attention is all you need.](https://arxiv.org/pdf/1706.03762.pdf), NuerIPS, 2017

## Vision-Only PTMs
### Well-Known Pretrain Models

**Vision Transformer**
[An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/pdf/2010.11929.pdf), ICLR, 2021.


**IPT**

[Pre-Trained Image Processing Transformer](https://arxiv.org/pdf/2012.00364.pdf), arXiv, 2020.

**DETR**

[End-to-End Object Detection with Transformers](https://arxiv.org/pdf/2005.12872.pdf), arXiv, 2020.

**DEFORMABLE DETR**

[Deformable DETR: Deformable Transformers for End-to-End Object Detection](https://arxiv.org/pdf/2010.04159.pdf), arXiv, 2020.

### Other Topics
[Modeling Techniques, Transfer Learning and Applications](https://github.com/AlenUbuntu/Awesome-Vision-and-Language-PreTrain-Models/blob/main/VisionOnlyPTMs.md)

## Language-Only PTMs
### Well-Known Pretrain Models
**ELECTRA** 

[ELECTRA: PRE-TRAINING TEXT ENCODERS AS DISCRIMINATORS RATHER THAN GENERATORS](https://arxiv.org/pdf/2003.10555.pdf), ICLR, 2020.

**ALBERT** 

[ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS](https://arxiv.org/pdf/1909.11942.pdf), ICLR, 2020.

**Longformer** 

[Longformer: The long-document transformer.](https://arxiv.org/pdf/2004.05150.pdf), arXiv, 2020.

**XLM**

[Cross-lingual Language Model Pretraining](https://arxiv.org/pdf/1901.07291.pdf), NeurIPS, 2019

**DistilBERT**

[DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/pdf/1910.01108.pdf), NeurIPS, 2019

**T5**

[Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/pdf/1910.10683.pdf), JMLR, 2019.

**Bart**

[BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://arxiv.org/pdf/1910.13461.pdf), ACL, 2019.

**XLNet**

[XLNet: Generalized Autoregressive Pretraining for Language Understanding.](https://proceedings.neurips.cc/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf), NIPS, 2019.

**Transformer-XL**

[Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context](https://arxiv.org/pdf/1901.02860.pdf), ACL, 2019.

**GPT/GPT2**

[Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), OpenAI blog, 2019

**RoBERTa**

[RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/pdf/1907.11692.pdf), arXiv, 2019.

**Bert**

[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf), NAACL, 2019.

### Other Topics
[Modeling Techniques, Transfer Learning and Applications](https://github.com/AlenUbuntu/Awesome-Vision-and-Language-PreTrain-Models/blob/main/LanguageOnlyPTMs.md)

## MultiModal PTMs
### Well-Known Pretrain Models
**MMBT**

[Supervised Multimodal Bitransformers for Classifying Images and Text](https://arxiv.org/pdf/1909.02950.pdf), arXiv, 2019

**MAG-BERT, MAG-XLNet**

[Integrating Multimodal Information in Large Pretrained Transformers.](https://www.aclweb.org/anthology/2020.acl-main.214.pdf), ACL, 2020.

**MART**

[MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning](https://www.aclweb.org/anthology/2020.acl-main.233.pdf), ACL, 2020.

**TaBERT**

[TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data.](https://www.aclweb.org/anthology/2020.acl-main.745.pdf), ACL, 2020.

**AV-ASR**

[Multiresolution and Multimodal Speech Recognition with Transformers](https://www.aclweb.org/anthology/2020.acl-main.216.pdf), ACL, 2020.

**Multimodal Transformer**

[Multimodal Transformer for Multimodal Machine Translation.](https://www.aclweb.org/anthology/2020.acl-main.400.pdf), ACL, 2020.

**Unified Multimodal Transformer**

[Improving Multimodal Named Entity Recognition via Entity Span Detection with Unified Multimodal Transformer](https://www.aclweb.org/anthology/2020.acl-main.306.pdf), ACL, 2020.

**X-LXMERT**

[X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal Transformers](https://www.aclweb.org/anthology/2020.emnlp-main.707.pdf), EMNLP, 2020.

**MTN**

[Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems](https://www.aclweb.org/anthology/P19-1564.pdf), ACL, 2019.

**MulT**

[Multimodal Transformer for Unaligned Multimodal Language Sequences](https://www.aclweb.org/anthology/P19-1656.pdf), ACL, 2019.

### Specific Topic
[Vision-Language-PTMs](https://github.com/AlenUbuntu/Awesome-Vision-and-Language-PreTrain-Models/blob/main/VL-PTMs.md)

